{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8d3Nh1NT3wk"
   },
   "source": [
    "# Model Training and Hyperparameter Tuning\n",
    "\n",
    "In this notebook we wil use preprocessed data to train our models and try to find the best set of hyperparameters. Here, I want to investigate how our model performs for different types of machine learning models such as Logistic Regression, SVM, Random Forests, Gradient Boosting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.20.3\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn==0.20.3) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn==0.20.3) (1.1.0)\n",
      "\u001b[31mfastai 1.0.50.post1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed scikit-learn-0.20.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyproj\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c8/090cd8eae755171959fac28d4bd537cc2caf168caadb92d8e505229c486b/pyproj-2.1.3-cp36-cp36m-manylinux1_x86_64.whl (10.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.8MB 4.4MB/s  eta 0:00:01\n",
      "\u001b[31mfastai 1.0.50.post1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyproj\n",
      "Successfully installed pyproj-2.1.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/42/f4b147fc7920998a42046d0c2e65e61000bc5d104f1f8aec719612cb2fc8/geopandas-0.5.0-py2.py3-none-any.whl (893kB)\n",
      "\u001b[K    100% |████████████████████████████████| 901kB 25.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from geopandas) (0.22.0)\n",
      "Requirement already satisfied: pyproj in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from geopandas) (2.1.3)\n",
      "Collecting fiona (from geopandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/4a/193cd6a75e51062c85f4e1cd6f312b3bbda6e26ba7510f152ef5016f0b16/Fiona-1.8.6-cp36-cp36m-manylinux1_x86_64.whl (17.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.9MB 2.8MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting shapely (from geopandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 38.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->geopandas) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->geopandas) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->geopandas) (1.15.4)\n",
      "Requirement already satisfied: click<8,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fiona->geopandas) (6.7)\n",
      "Requirement already satisfied: six>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fiona->geopandas) (1.11.0)\n",
      "Collecting click-plugins>=1.0 (from fiona->geopandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
      "Collecting munch (from fiona->geopandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n",
      "Requirement already satisfied: attrs>=17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from fiona->geopandas) (18.1.0)\n",
      "Collecting cligj>=0.5 (from fiona->geopandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
      "Building wheels for collected packages: munch\n",
      "  Running setup.py bdist_wheel for munch ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n",
      "Successfully built munch\n",
      "\u001b[31mfastai 1.0.50.post1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: click-plugins, munch, cligj, fiona, shapely, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.6 geopandas-0.5.0 munch-2.3.2 shapely-1.6.4.post2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1557002909862,
     "user": {
      "displayName": "Victor Oliveira",
      "photoUrl": "",
      "userId": "10089332720080278443"
     },
     "user_tz": 180
    },
    "id": "oOfZPeUHPb5D",
    "outputId": "9500141a-488b-458e-b853-098d657e0589"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPXmy74CW7ov"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100547, 1431), (33516, 1431))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data into train/test sets\n",
    "\n",
    "data_sequence = pd.read_hdf('../data/preprocessed/data_sequence_alldata.hdf', key='final_alldata', mode='r')\n",
    "data_sequence = data_sequence.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "with open('../data/preprocessed/hashs_train.pkl', 'rb') as fp:\n",
    "    hashs_train = pickle.load(fp)\n",
    "    \n",
    "with open('../data/preprocessed/hashs_test.pkl', 'rb') as fp:\n",
    "    hashs_test = pickle.load(fp)\n",
    "\n",
    "window_reference = 5\n",
    "\n",
    "train = data_sequence[data_sequence.hash.isin(hashs_train)]\n",
    "train = train[train['hour_exit_'+str(window_reference)]>=15]\n",
    "\n",
    "test  = data_sequence[data_sequence.hash.isin(hashs_test)]\n",
    "\n",
    "train_train, train_val = train_test_split(train, test_size=0.25, random_state=20)\n",
    "train_train.shape, train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfTTekNtgKzI"
   },
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/original_columns_alldata.pkl', 'rb') as fp: \n",
    "    original_cols = pickle.load(fp)\n",
    "    \n",
    "drop_cols = list(x for x in original_cols if 'exit' in x)# + grid_cols\n",
    "drop_cols += ['lat_lon_entry', 'lat_lon_exit']\n",
    "drop_cols += ['euclidean_distance', 'manhattan_distance', 'harvesine_distance',\n",
    "              'center_permanency', 'crossed_city', 'velocity', 'leaving_city', 'entering_city']\n",
    "\n",
    "drop_cols = [col+'_'+str(window_reference) for col in drop_cols]\n",
    "#drop_cols += [col+'_'+str(i) for col in grid_cols for i in range(0, 5)]\n",
    "drop_cols += ['hash', f'delta_last_center_permanency_{window_reference}', f'delta_origin_center_permanency_{window_reference}']\n",
    "\n",
    "features = list(set(train.columns) - set(drop_cols))\n",
    "target   = ['is_inside_city_exit_'+str(window_reference)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TO BE DELETED #####################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train = train_train[train_train.euclidean_distance_5!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8448881700039043"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model    = LogisticRegression(random_state=20, penalty='l1', C=1)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "\n",
    "pipeline.fit(train_train[features], train_train[target])\n",
    "predicted = pipeline.predict(train_val[features])\n",
    "\n",
    "f1_score(train_val[target], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached https://files.pythonhosted.org/packages/77/0f/5157e6b153b3d4a70dc5fbe2ab6f209604197590f387f03177b7a249ac60/lightgbm-2.2.3-py2.py3-none-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (0.20.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (1.15.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (1.1.0)\n",
      "\u001b[31mfastai 1.0.50.post1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8866945606694562"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "best_params_lgb = {'boosting_type': 'gbdt', \n",
    "                 'colsample_bytree': 1.0, \n",
    "                 'is_unbalance': False, \n",
    "                 'max_depth': -1, \n",
    "                 'n_estimators': 150, \n",
    "                 'num_leaves': 31, \n",
    "                 'objective': 'binary', \n",
    "                 'random_state': 20, \n",
    "                 'reg_alpha': 1, \n",
    "                 'subsample': 1}\n",
    "\n",
    "clf = lgb.LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])\n",
    "predicted = clf.predict(train_val[features])\n",
    "f1_score(train_val[target], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/a8/16637c4958c371b33653280f787d9ab5b78226608f99b38f9e009f394f48/catboost-0.15-cp36-none-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.16.0 (from catboost)\n",
      "  Using cached https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting graphviz (from catboost)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catboost) (0.22.0)\n",
      "Collecting enum34 (from catboost)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2.7.3)\n",
      "\u001b[31mfastai 1.0.50.post1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.1 has requirement msgpack<0.6.0,>=0.5.6, but you'll have msgpack 0.6.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, graphviz, enum34, catboost\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "Successfully installed catboost-0.15 enum34-1.1.6 graphviz-0.10.1 numpy-1.16.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/__init__.py\", line 167, in <module>\n",
      "    core.getlimits._register_known_types()\n",
      "AttributeError: module 'numpy.core.getlimits' has no attribute '_register_known_types'\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/__init__.py\", line 32, in <module>\n",
      "    __all__ += type_check.__all__\n",
      "NameError: name 'type_check' is not defined\n",
      "]\n",
      "[autoreload of numpy.core failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/__init__.py\", line 91, in <module>\n",
      "    raise ImportError(msg.format(path))\n",
      "ImportError: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.\n",
      "]\n",
      "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/numeric.py\", line 3098, in <module>\n",
      "    extend_all(umath)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/numeric.py\", line 3085, in extend_all\n",
      "    mall = getattr(module, '__all__')\n",
      "AttributeError: module 'numpy.core.umath' has no attribute '__all__'\n",
      "]\n",
      "[autoreload of numpy.core.records failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/records.py\", line 45, in <module>\n",
      "    from numpy.compat import isfileobj, bytes, long, unicode, os_fspath\n",
      "ImportError: cannot import name 'os_fspath'\n",
      "]\n",
      "[autoreload of numpy.core.memmap failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/memmap.py\", line 5, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath'\n",
      "]\n",
      "[autoreload of numpy.testing failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/testing/__init__.py\", line 18, in <module>\n",
      "    __all__ = _private.utils.__all__ + ['TestCase', 'run_module_suite']\n",
      "NameError: name '_private' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.function_base failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/function_base.py\", line 35, in <module>\n",
      "    from numpy.core.multiarray import (\n",
      "ImportError: cannot import name '_monotonicity'\n",
      "]\n",
      "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/matrixlib/__init__.py\", line 8, in <module>\n",
      "    __all__ = defmatrix.__all__\n",
      "NameError: name 'defmatrix' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.mixins failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/mixins.py\", line 63, in <module>\n",
      "    class NDArrayOperatorsMixin(object):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/mixins.py\", line 156, in NDArrayOperatorsMixin\n",
      "    um.matmul, 'matmul')\n",
      "AttributeError: module 'numpy.core.umath' has no attribute 'matmul'\n",
      "]\n",
      "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 25, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath'\n",
      "]\n",
      "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/format.py\", line 164, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath'\n",
      "]\n",
      "[autoreload of numpy.polynomial.polynomial failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "[autoreload of numpy.polynomial.chebyshev failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "[autoreload of numpy.polynomial.legendre failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "[autoreload of numpy.polynomial.hermite_e failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "[autoreload of numpy.polynomial.laguerre failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 278, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object '_catboost._FloatArrayWrapper' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9acce74162aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/catboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEFstrType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_models\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'FeaturesData'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EFstrType'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostClassifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostRegressor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatBoostError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CatboostError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# API compatibility alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0m_catboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_catboost_bin_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0m_PoolBase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PoolBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0m_CatBoost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CatBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mget_catboost_bin_module\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mso_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mso_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloaded_catboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_catboost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'catboost._catboost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36minit _catboost\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object '_catboost._FloatArrayWrapper' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbc = CatBoostClassifier(verbose=0)\n",
    "cbc.fit(train_train[features], train_train[target])\n",
    "\n",
    "predicted = cbc.predict(train_val[features])\n",
    "f1_score(train_val[target], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not '_NoValueType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3fcd405bcc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# false positives from overflow in sum method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not '_NoValueType'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=7)\n",
    "rf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### TO BE DELETED #####################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGZivPipUVHz"
   },
   "source": [
    "## 1. Logistic Regression\n",
    "\n",
    "The first model we will consider is the simple linear model Logistic Regression. I will use a GridSearch approach to cross-validate results using k-fold schema to find the best set of hyperparameters.\n",
    "\n",
    "It is important to note that hyperparameter tuning is done using k-folds using only training data, that is, our test set will use to assess the parameters found and will not be used to choose the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed: 74.4min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 98.7min\n",
      "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed: 101.2min\n",
      "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed: 106.9min\n",
      "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed: 107.3min\n",
      "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed: 147.9min\n",
      "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed: 152.5min\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__C': [0.01, 0.1, 20],\n",
    "             'model__penalty':['l1', 'l2'],\n",
    "             'model__class_weight':[None, 'balanced'],\n",
    "             'scaler':[StandardScaler(), MinMaxScaler()]}\n",
    "\n",
    "model    = LogisticRegression(random_state=20)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=2, scoring='f1', refit='f1')\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/cv_results_logistic_regression.pkl', 'wb') as fp:\n",
    "    pickle.dump(clf.cv_results_, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4bef1fbf33c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__n_neighbors': [3, 11, 31, 75],\n",
    "             'model__weights': ['uniform', 'distance']}\n",
    "\n",
    "model    = KNeighborsClassifier(n_jobs=-1)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=-1, scoring='f1', refit='f1')\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/cv_results_knn.pkl', 'wb') as fp:\n",
    "    pickle.dump(clf.cv_results_, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 . LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-54799cffadf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Print the best parameters found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'num_leaves': [31, 42],\n",
    "    'random_state' : [20], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.8, 1.0],\n",
    "    'subsample' : [0.5, 0.75, 1.0],\n",
    "    'max_depth': [7, 15, 25, -1]\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "clf = lgb.LGBMClassifier()\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "# Create the grid\n",
    "grid = GridSearchCV(clf, gridParams, verbose=20, cv=splitter, n_jobs=-1, scoring='f1', refit='f1')\n",
    "# Run the grid\n",
    "#grid.fit(train_train[features], train_train[target])\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LightGBM F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LightGBM F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411027568922306"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "best_params_lgb = {'boosting_type': 'gbdt', \n",
    "                 'colsample_bytree': 1.0, \n",
    "                 'is_unbalance': False, \n",
    "                 'max_depth': 7, \n",
    "                 'n_estimators': 150, \n",
    "                 'num_leaves': 31, \n",
    "                 'objective': 'binary', \n",
    "                 'random_state': 20, \n",
    "                 'reg_alpha': 1, \n",
    "                 'subsample': 0.7}\n",
    "\n",
    "clf = lgb.LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])\n",
    "clf.score(train_val[features], train_val[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25012\n",
       "1.0     8503\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_sequence[data_sequence.hash.isin(hashs_test)]\n",
    "ids = pd.read_csv('../data/raw/data_test.zip', index_col='Unnamed: 0', low_memory=True)\n",
    "ids = ids[ids.x_exit.isnull()]\n",
    "data_test = data_test.merge(ids[['hash', 'trajectory_id']], on='hash')\n",
    "\n",
    "clf = lgb.LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "clf.fit(train[features], train[target])\n",
    "yhat = clf.predict(data_test[features])\n",
    "\n",
    "pd.Series(yhat).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(data_test['trajectory_id'], yhat)), columns=['id', 'target'])\n",
    "submission.to_csv('../data/submission92_victor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21473648,
     "status": "ok",
     "timestamp": 1557024584753,
     "user": {
      "displayName": "Victor Oliveira",
      "photoUrl": "",
      "userId": "10089332720080278443"
     },
     "user_tz": 180
    },
    "id": "ggn4--W6TXxT",
    "outputId": "264140f1-2752-4320-8528-1cfeacc64c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed: 22.4min\n"
     ]
    }
   ],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__C': [0.01, 0.1, 10, 20],\n",
    "             'model__penalty':['l1', 'l2'],\n",
    "             'model__fit_intercept': [True, False],\n",
    "             'model__class_weight':[None, 'balanced'],\n",
    "              'model__n_jobs':[8],\n",
    "             'scaler':[StandardScaler(), MinMaxScaler()]}\n",
    "\n",
    "model    = LogisticRegression(random_state=20, n_jobs=-1)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=-1)\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of  12 | elapsed: 43.8min remaining: 43.8min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  12 | elapsed: 75.9min remaining: 54.2min\n",
      "[Parallel(n_jobs=4)]: Done   8 out of  12 | elapsed: 76.8min remaining: 38.4min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  12 | elapsed: 81.3min remaining: 27.1min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  12 | elapsed: 82.3min remaining: 16.5min\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed: 189.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed: 189.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'model__n_estimators': [200],\n",
    "    'model__max_features' : [0.5, 'sqrt'],\n",
    "    'model__max_depth': [7, 15, None]\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "model    = RandomForestClassifier(random_state=20)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('model', model)])\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "# Create the grid\n",
    "grid = GridSearchCV(pipeline, gridParams, verbose=20, cv=splitter, n_jobs=4, scoring='f1', refit='f1')\n",
    "# Run the grid\n",
    "grid.fit(train_train[features], train_train[target])\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = CatBoostClassifier(verbose=0)\n",
    "cbc.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc.score(train_val[features])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "victor-training-classification-models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8d3Nh1NT3wk"
   },
   "source": [
    "# Model Training and Hyperparameter Tuning\n",
    "\n",
    "In this notebook we wil use preprocessed data to train our models and try to find the best set of hyperparameters. Here, I want to investigate how our model performs for different types of machine learning models such as Logistic Regression, SVM, Random Forests, Gradient Boosting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1557002909862,
     "user": {
      "displayName": "Victor Oliveira",
      "photoUrl": "",
      "userId": "10089332720080278443"
     },
     "user_tz": 180
    },
    "id": "oOfZPeUHPb5D",
    "outputId": "9500141a-488b-458e-b853-098d657e0589"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPXmy74CW7ov"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100547, 1431), (33516, 1431))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data into train/test sets\n",
    "\n",
    "data_sequence = pd.read_hdf('../data/preprocessed/data_sequence_alldata.hdf', key='final_alldata', mode='r')\n",
    "data_sequence = data_sequence.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "with open('../data/preprocessed/hashs_train.pkl', 'rb') as fp:\n",
    "    hashs_train = pickle.load(fp)\n",
    "    \n",
    "with open('../data/preprocessed/hashs_test.pkl', 'rb') as fp:\n",
    "    hashs_test = pickle.load(fp)\n",
    "\n",
    "window_reference = 5\n",
    "\n",
    "train = data_sequence[data_sequence.hash.isin(hashs_train)]\n",
    "train = train[train['hour_exit_'+str(window_reference)]>=15]\n",
    "\n",
    "test  = data_sequence[data_sequence.hash.isin(hashs_test)]\n",
    "\n",
    "train_train, train_val = train_test_split(train, test_size=0.25, random_state=20)\n",
    "train_train.shape, train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfTTekNtgKzI"
   },
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/original_columns_alldata.pkl', 'rb') as fp: \n",
    "    original_cols = pickle.load(fp)\n",
    "    \n",
    "drop_cols = list(x for x in original_cols if 'exit' in x)# + grid_cols\n",
    "drop_cols += ['lat_lon_entry', 'lat_lon_exit']\n",
    "drop_cols += ['euclidean_distance', 'manhattan_distance', 'harvesine_distance',\n",
    "              'center_permanency', 'crossed_city', 'velocity', 'leaving_city', 'entering_city']\n",
    "\n",
    "drop_cols = [col+'_'+str(window_reference) for col in drop_cols]\n",
    "#drop_cols += [col+'_'+str(i) for col in grid_cols for i in range(0, 5)]\n",
    "drop_cols += ['hash', f'delta_last_center_permanency_{window_reference}', f'delta_origin_center_permanency_{window_reference}']\n",
    "\n",
    "features = list(set(train.columns) - set(drop_cols))\n",
    "target   = ['is_inside_city_exit_'+str(window_reference)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGZivPipUVHz"
   },
   "source": [
    "## 1. Logistic Regression\n",
    "\n",
    "The first model we will consider is the simple linear model Logistic Regression. I will use a GridSearch approach to cross-validate results using k-fold schema to find the best set of hyperparameters.\n",
    "\n",
    "It is important to note that hyperparameter tuning is done using k-folds using only training data, that is, our test set will use to assess the parameters found and will not be used to choose the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed: 74.4min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 98.7min\n",
      "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed: 101.2min\n",
      "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed: 106.9min\n",
      "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed: 107.3min\n",
      "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed: 147.9min\n",
      "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed: 152.5min\n",
      "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed: 152.5min\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__C': [0.01, 0.1, 20],\n",
    "             'model__penalty':['l1', 'l2'],\n",
    "             'model__class_weight':[None, 'balanced'],\n",
    "             'scaler':[StandardScaler(), MinMaxScaler()]}\n",
    "\n",
    "model    = LogisticRegression(random_state=20)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=2, scoring='f1', refit='f1')\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/cv_results_logistic_regression.pkl', 'wb') as fp:\n",
    "    pickle.dump(clf.cv_results_, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__n_neighbors': [3, 11, 31, 75],\n",
    "             'model__weights': ['uniform', 'distance']}\n",
    "\n",
    "model    = KNeighborsClassifier(n_jobs=-1)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=-1, scoring='f1', refit='f1')\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/cv_results_knn.pkl', 'wb') as fp:\n",
    "    pickle.dump(clf.cv_results_, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 . LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'num_leaves': [31, 42],\n",
    "    'random_state' : [20], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.8, 1.0],\n",
    "    'subsample' : [0.5, 0.75, 1.0],\n",
    "    'max_depth': [7, 15, 25, -1]\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "clf = lgb.LGBMClassifier()\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "# Create the grid\n",
    "grid = GridSearchCV(clf, gridParams, verbose=20, cv=splitter, n_jobs=-1, scoring='f1', refit='f1')\n",
    "# Run the grid\n",
    "grid.fit(train_train[features], train_train[target])\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LightGBM F1-Score on CV data: {}\".format(clf.best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LightGBM F1-Score on Holdout data: {}\".format(clf.score(train_val[features], train_val[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411027568922306"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "best_params_lgb = {'boosting_type': 'gbdt', \n",
    "                 'colsample_bytree': 1.0, \n",
    "                 'is_unbalance': False, \n",
    "                 'max_depth': 7, \n",
    "                 'n_estimators': 150, \n",
    "                 'num_leaves': 31, \n",
    "                 'objective': 'binary', \n",
    "                 'random_state': 20, \n",
    "                 'reg_alpha': 1, \n",
    "                 'subsample': 0.7}\n",
    "\n",
    "clf = lgb.LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])\n",
    "clf.score(train_val[features], train_val[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25012\n",
       "1.0     8503\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_sequence[data_sequence.hash.isin(hashs_test)]\n",
    "ids = pd.read_csv('../data/raw/data_test.zip', index_col='Unnamed: 0', low_memory=True)\n",
    "ids = ids[ids.x_exit.isnull()]\n",
    "data_test = data_test.merge(ids[['hash', 'trajectory_id']], on='hash')\n",
    "\n",
    "clf = lgb.LGBMClassifier(**best_params_lgb)\n",
    "\n",
    "clf.fit(train[features], train[target])\n",
    "yhat = clf.predict(data_test[features])\n",
    "\n",
    "pd.Series(yhat).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(data_test['trajectory_id'], yhat)), columns=['id', 'target'])\n",
    "submission.to_csv('../data/submission92_victor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21473648,
     "status": "ok",
     "timestamp": 1557024584753,
     "user": {
      "displayName": "Victor Oliveira",
      "photoUrl": "",
      "userId": "10089332720080278443"
     },
     "user_tz": 180
    },
    "id": "ggn4--W6TXxT",
    "outputId": "264140f1-2752-4320-8528-1cfeacc64c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed: 22.4min\n"
     ]
    }
   ],
   "source": [
    "# defining parameters search\n",
    "parameters = {'model__C': [0.01, 0.1, 10, 20],\n",
    "             'model__penalty':['l1', 'l2'],\n",
    "             'model__fit_intercept': [True, False],\n",
    "             'model__class_weight':[None, 'balanced'],\n",
    "              'model__n_jobs':[8],\n",
    "             'scaler':[StandardScaler(), MinMaxScaler()]}\n",
    "\n",
    "model    = LogisticRegression(random_state=20, n_jobs=-1)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', MinMaxScaler()), ('model', model)])\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "\n",
    "clf   = GridSearchCV(pipeline, param_grid=parameters, cv=splitter, verbose=20, n_jobs=-1)\n",
    "\n",
    "clf.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of  12 | elapsed: 43.8min remaining: 43.8min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  12 | elapsed: 75.9min remaining: 54.2min\n",
      "[Parallel(n_jobs=4)]: Done   8 out of  12 | elapsed: 76.8min remaining: 38.4min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  12 | elapsed: 81.3min remaining: 27.1min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  12 | elapsed: 82.3min remaining: 16.5min\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed: 189.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed: 189.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'model__n_estimators': [200],\n",
    "    'model__max_features' : [0.5, 'sqrt'],\n",
    "    'model__max_depth': [7, 15, None]\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "model    = RandomForestClassifier(random_state=20)\n",
    "imputer  = SimpleImputer(strategy='constant', fill_value=0)\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('model', model)])\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=2, random_state=2)\n",
    "# Create the grid\n",
    "grid = GridSearchCV(pipeline, gridParams, verbose=20, cv=splitter, n_jobs=4, scoring='f1', refit='f1')\n",
    "# Run the grid\n",
    "grid.fit(train_train[features], train_train[target])\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = CatBoostClassifier(verbose=0)\n",
    "cbc.fit(train_train[features], train_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc.score(train_val[features])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "victor-training-classification-models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
